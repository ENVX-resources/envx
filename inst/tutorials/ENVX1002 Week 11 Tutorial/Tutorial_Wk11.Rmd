---
title: "ENVX1002 Tutorial week 11"
author: 
  - Liana Pozza
  - ----
  - "**ENVX1002 Introduction to Statistical Methods**"
  - School of Life and Environmental Science
  - The University of Sydney
  - ----
output: 
  learnr::tutorial:
    theme: cosmo
    language: 
      en:
        button:
          nexttopic: Next Page
          previoustopic: Previous Page
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
knitr::opts_chunk$set(
	cache = TRUE,
	output = FALSE
)
```

## What we will cover in this tutorial

Building upon what has been covered in the lecture, we will walk through a similar case study to last week, but this time applying the main steps of multiple linear regression and how to interpret the output. Similar to last week, for this tutorial we will use a subset of data from my own work mapping sodicity across the Murray-Darling Basin. 

This time though, the data is slightly different; rather than topsoil samples like last week, the ESP data is now collected from 55 cm depth in the soil profile - how well can the remote sensing data account for variation in ESP at depth?

## The problem

The aim of my study was to find a better way to predict sodicity in soils across the Murray-Darling Basin. 

The Murray-Darling Basin encompasses a huge portion of Eastern Australia (approx. 1,059,000 km^2^; ABS 2015) and is a significant area of agricultural production, annually contributing $24 billion food and fibre to the Australian Economy. 

![Image: Map of Australia with Murray-Darling Basin outlined in red.](images/MDB_Australia_map.jpg){width=100%}


### What is sodicity?

Sodicity is where excess amounts of sodium accumulate in the soil profile and affects the structure of soil, impacting upon plant growth and soil stability. 

Therefore, landowners, managers and government want to know where sodicity is occurring so they can manage for it. We would do this through soil sampling, but sampling can end up quite expensive. We want to find a way to produce a continuous picture that is as accurate as possible and makes it cheaper for those interested who need to know where the sodicity is occurring. A way around this is by modelling and mapping. 

![Image: Erosion resulting from high levels of sodicity in the soil](images/sodicity.png)

### 
Modelling allows us to predict our response variable based on a shared relationship with something else. There are many factors which influence sodicity such as elevation and rainfall, but today we will select a small number of predictors and see how well the model fits to the data. 

The response variable for our models will be Exchangeable Sodium Percentage (ESP), which is a measure of sodium present in the soil. 

The dataset I have sourced ESP from was obtained from the National Soil Site Collation ([NSSC](https://researchdata.edu.au/csiro-national-soil-site-database/444301)). The NSSC is a freely accessible database compiled from a range of soil surveys conducted within the last 50 years. This dataset is huge, so I have taken a random subset of 95 samples using the `sample()` function in R.  

We are very lucky to live in an age where we can access freely-available remote sensing data relating to the landscape, and there is potential for these variables to possess a relationship with sodicity, enabling us to fit a model for relatively cheaper cost. I have obtained a set of covariates (predictors) corresponding to the same spatial location as the ESP samples. 

### Data dictionary

The remote sensing data I have obtained are as follows: 

Terrain attributes, linked to soil properties and water runoff

* DEM_30 = Elevation, measured in metres
* Aspect = Direction of slope, measured in radians
* MrRTF = Multi-resolution ridge top flatness index
* SlopeDeg = Slope, measured in degrees

Airborne radiometrics, linked to geomorphology and soil type

* rad_k = Potassium detected by airborne radiometrics sensor, measured in %
* rad_th = Thorium detected by airborne radiometrics sensor, measured in %
* rad_u = Uranium detected by airborne radiometrics sensor, measured in %

Satellite indices reflecting plant dynamics and ground cover

* NDVI_50 = Normalized Difference Vegetation Index (NDVI) 50th percentile compiled over 20 years
* RED_50 = Satellite red band 50th percentile compiled over 20 years

Climate variables, influences flushing of salts and evaporation

* rain = Mean annual rainfall 1926 to 2005
* temp = Mean annual temperature 1926 to 2005

All of these variables have the potential to influence ESP in the soil profile; however, it would be unwise to try fitting the model with every single predictor we have, especially with so few samples (n=50). 

Therefore we will explore the predictors through correlation analysis and select those which are most strongly related to ESP for our multiple linear regression. 


## Data prep

### Reading in data 

First of all, don't forget to set up a project containing your data and open up/save a fresh Quarto document. 

Next we can read in the data: 

```{r read}

dat = read.csv("ENVX1002_Tutorial_Week11.csv", header=T)

```


###

Let's check out the structure, what are the variable types within the dataframe?

```{r structure}

str(dat)

```

Notice all of the variables are numeric (and therefore continuous), except the column labelled 'Site' which is a character variable (categorical) and serves as the unique ID for each site. I have left this in for good practice - the more complex analyses get, you want to be able to relate your results back to the original samples, especially if mapping as I have been. 

### Selecting variables of interest

We shall reduce the size of the dataset to only those variables we will be using to fit our multiple linear regression. We will select our response variable (ESP), but we also need to work out which variables are most strongly correlated with ESP. 

```{r cor}

# View(as.data.frame(cor(dat[-c(1)])))

cor(dat[-c(1)])

# winners: 
# MrRTF: 0.5825
# SlopeDeg: -0.4449
# rad_k: -0.4407
# NDVI_50: -0.4219
# temp: 0.3936

```

###
It is also important to check for correlations between the predictor variables. In this case, the strongest correlation among our winning variables is between MrRTF and NDVI_50 (r = -0.6479), which is not overly high, but worth keeping note of during interpretation of the final model. 

###
Now we have a set of winners, we can subset the data. 

I have used the names() function below to identify the column locations of each variable:

```{r subset}

## winners: 
## MrRTF: 0.5825
## SlopeDeg: -0.4449
## rad_k: -0.4407
## NDVI_50: -0.4219
## temp: 0.3936

names(dat)

# Extract certain columns from the 'dat' dataframe
sub = dat[,c(4, 7, 8, 9, 12, 15)]

names(sub)

```

###
And if interested in prettier output, we can rerun the correlation:

```{r cor_sub}

cor(sub)

```


## Exploratory analysis

### Plotting 

For simple linear regression, it was possible to produce a simple x-y plot, but now our data is multidimensional, it is much harder to visualise.  

The pairs plot does a sufficient job for us, creating plots against all of the variables, which allows us to visualise any (linear or nonlinear) relationships occurring between response and predictors, and among the predictors. 

It is also possible to create 3D plots, as you will see in the practical, but for the exploratory analysis, the pairs plot is sufficient. 

```{r pairs_plot}

pairs(sub)

```


The pairs plots support the correlation coefficients we obtained, as we can see it is possible to draw a line that many of the points follow, on many of the plots; however, they may not follow too closely. 

Last week we also noted some outliers in the plot, but this time as there are so many plots it is much harder to see. We are better off looking at measures of spread and center.

### Spread and centre

After investigating visually, want to have an understanding of the spread and centre of the data. This will also assist later with model interpretation.  

```{r summary}

summary(sub)

```

Looking at the summary output, the spread seems reasonable, makes sense - e.g. NDVI should be a value between 0 and 1, and slope of 9 degrees is quite steep, but still a real value. The ESP also contains some higher values which may be outliers, but the value is still a realistic value (<40% ESP)

We can also see the means and medians are quite similar for most, except ESP, so it is worth obtaining the skewness coefficient and fitting a boxplot. 

```{r skew}

library(moments)
skewness(sub)

boxplot(sub$ESP)

```


By observing the skewness, we can see ESP is not as skewed as I thought. Instead, slope is the most skewed variable, which may be worth investigating further to improve fit, but for now I will keep it untransformed.

## Modelling

### State aims and hypotheses

How well can the remote sensing data account for variation in ESP at depth?

Aim: To investigate how much variation in sodicity (ESP) is accounted for by our selected freely-available remote sensing data. 

Remember as we are fitting a multiple linear regression, we will be testing two sets of hypotheses. 

### Set 1: Is the model significant?

$H_0 : All\: \beta_k = 0$

$H_1 : At\: least\: 1\: \beta_k \neq{0}$

We will test this by observing the results of the F-test at the end of the model output. The F statistic is a ratio of the RSS for the fitted model, and the RSS of a model which only includes the intercept. A significant P-value for the F-test tells us our fitted model (full model) is much better than the intercept-only model (reduced model). 

### Set 2: Are our predictors significant?

$H_0 : \beta_k = 0$; slope of the fitted model = 0; therefore we could conclude that our selected variable would not be a good predictor of ESP, and we would be better off using the mean ($\bar{y}$).  

$H_1 : \beta_k \neq{0}$; slope of the fitted model $\neq$ 0, therefore we could conclude that our selected variable would indeed be a good predictor of ESP.

The t-test is conducted for each of the predictor variables, with the test comparing a model with and without the selected variable. If we fail to reject $H_0$, we are saying the model is better without the predictor as it doesn't cause significant improvement in the fit. IF we reject $H_0$ we are saying the predictor significantly improves model fit and should not be removed. 

### Fit the model

```{r set_seed, echo=FALSE}
set.seed(42)
```

```{r fit_lm}

names(sub)

mod = lm(ESP ~ MrRTF + SlopeDeg + rad_k + NDVI_50 + temp, data=sub)

```


### Check assumptions

```{r assumptions}

## set plots to display in 2x2 matrix rather than one at a time
par(mfrow=c(2,2))

plot(mod)

```

* Residuals vs fitted (L): Borderline met. Points mostly scattered about the mean, but red line (the mean) doesn't follow the dotted line as expected. The slight upward curve of the mean suggests the relationship may not be linear. We can contnue, but not expect our model to completely represent the relationship. 
* Normal Q-Q (N): Majority of the points lie on the line; therefore Residuals normally distributed.
* Scale-Location (E): Generally evenly scattered, light fanning if anything and line is mostly straight. Homogeneity of variance in the residuals has been met. 
* Residuals vs leverage (I): No points lying in the top or bottom right corners or bordering the 0.5 boundary, indicating no specific points significantly influencing the model. 

Observing the plots, we can conclude the assumptions have now been met, but keeping in mind this may not be the best model in the end. 

Let's continue to interpretation of or model.


## Interpret model output
###
```{r}

summary(mod)

```

We will read through the output top-down. 

###

The first aspect of the output tells us what the input equation was:
```{r call, echo=FALSE}
summary(mod)[1]
```

Nothing too exciting, can see that none of our variables have been transformed, and we have many more predictor variables, so interpretation is going to be slightly different to last week.   

###

Next aspect we see in the model summary, is a summary of the model residuals:
```{r res, echo=FALSE}
summary(mod$residuals)
```

The above summary can provide an idea of the distribution/symmetry of the residuals. From the output, we can see the residuals look relatively symmetrical, which ties in with the residuals vs fitted and Normal Q-Q plot we saw when checking our assumptions. 

### Interpreting model coefficients

Now the fun part, we can look at our model coefficients:
```{r coeff, echo=FALSE}
summary(mod)[4]
```

Under `Estimate` we can draw out our values for $b_0$ and $b_1$ to $b_4$ and write the model equation. 

- $b_0$ = 5.7208 (Intercept)
- $b_1$ = 1.3670 (MrRTF)
- $b_2$ = -0.2434 (SlopeDeg)     
- $b_3$ = -6.0582 (rad_k)
- $b_4$ =  3.8796 (NDVI_5)
- $b_5$ =  0.2094 (temp)

Notation for the coefficients can be in any order (i.e. $b_3$ could refer to MrRTF), I just went in order of the output. 

Therefore: 

###

ESP = 5.7208 + 1.3670 * MrRTF -0.2434 * SlopeDeg -0.2434 * rad_k + 3.8796 * NDVI_5 + 0.2094 * temp 

How do we interpret the estimate?

General statement: 

> “as $x_1$ increases by 1, y decreases by $b_1$ units* given all other partial regression coefficients are held constant”

*Units refers to the units of the response variable

<br>

More specifically: 

> "As MrRTF increases by 1, ESP increases by 1.3670%, given all other variables are held constant."

> "As SlopeDeg increases by 1, ESP DECREASES by 0.2434%, given all other variables are held constant." (decreases because of negative coefficient)

> "As rad_k increases by 1, ESP decreases by 6.0582%, given all other variables are held constant." 

> "As NDVI_50 increases by 1, ESP increases by 3.8796%, given all other variables are held constant."

> "As temp increases by 1, ESP increases by 0.2094, given all other variables are held constant."


### Hypothesis testing

From earlier, we are testing two main sets of hypotheses for our multiple linear regression: 

### Set 1: Is the model significant?

$H_0 : All\: \beta_k = 0$

$H_1 : At\: least\: 1\: \beta_k \neq{0}$

We will test this by observing the results of the F-test at the end of the model output. 

```{r}
summary(mod)
```

We can see the P-value for our F-statistic is much smaller than 0.05 (P = 0.0001095), so we reject the null hypothesis and conclude the model is significant. This means at least one of our predictor variables are significant, and the model fits better than the model fit with only the intercept. 

### Set 2: Are our predictors significant?

$H_0 : \beta_k = 0$; slope of the fitted model = 0; therefore we could conclude that our selected variable would not be a good predictor of ESP, and we would be better off using the mean ($\bar{y}$).  

$H_1 : \beta_k \neq{0}$; slope of the fitted model $\neq$ 0, therefore we could conclude that our selected variable would indeed be a good predictor of ESP.

The t-test is conducted for each of the predictor variables, with the test comparing a model with and without the selected variable. 

In the summary we can see there are two significant predictors (P<0.05), MrRTF (P = 0.006) and rad_k (P = 0.028). The remaining predictors are non-significant, suggesting they do not make a significant improvement to the model fit. 

It would be better to make our model more parsimonious by excluding the non-significant predictors. To do this we can remove the least significant predictor each time and rerun the model until only significant predictors remain. We will have a brief look at this at the end of the interpretation; predictor elimination and model reduction is covered in more detail in ENVX2001. 


### Model fit statistics

The final portion of the model summary includes Residual standard error, r^2^ values and F-statistic:

```{r lastbit, echo=FALSE}

summary(mod)

```

The closer the residual standard error is to zero, the better, and the value is on the same scale as the response variable. In this case the residual standard error is easier to interpret as it is untransformed. If we remember back to our summary of ESP, the values ranged from 0 to 32, so a Residual Standard Error of 6.4 is not too bad, but could be better. 

On that same line we can see the degrees of freedom, which in this case is 45. We can work this out as follows: 

df = n-(p+1), where n = number of observations, p = number of predictors, and the 1 accounts for the intercept. In the dataset we have 50 observations and in the model we have 5 predictors, therefore df = 50-(5+1) = 44. 

The next line contains the multiple r-squared and adjusted r-squared. For multiple linear regression we refer to the **adjusted** r-squared, which in this case is 0.3654. This value is much closer to 0 than to 1, indicating a poor model fit, and our model only accounts for 36.5% of variation in ESP. 

## Making conclusions

### Statistical conclusion

For the statistical conclusion we are reporting the results of our hypothesis tests:  

Observing the model output, and in particular the output for the F-test, we can see that our model is significant (P<0.05) and so we can reject the null hypothesis. By rejecting the null hypothesis we can conclude at least one predictor is significant within the model, and our model fits significantly better than the intercept-only model. 

Furthermore, in support of the F-test results, the t-test results indicate there are two significant predictors in the model (MrRTF and rad_k; P = 0.006 and 0.028, respectively), allowing us to reject the null hypothesis for these partial regression coefficients alone. The remaining predictors are non-significant (P>0.05) therefore we fail to retain the null hypotheses for these predictors, stating the model may be better without them. 

### Scientific conclusion

We can then report the results in the context of our original aim: 

We can conclude that not all of our selected remote sensing variables are significant predictors of ESP at 55cm depth in the profile. The model was significant, and MrRTF and radiometrics-potassium were significant predictors of ESP (P<0.05). Although significant, the model only accounts for 36.5% of variation in ESP, so further exploration into  alternative predictor combinations or modelling methods is needed.

## Impact of excluding non-significant covariates
###
To make the model more parsimonious, it is worth exploring whether removal of the non-significant predictors improves the model fit. 

```{r}

mod2 = lm(ESP ~ MrRTF + rad_k, data=sub)

summary(mod2)
```

###
```{r}
summary(mod)
```

Impact: 

* Significant predictors have become more significant
* Model fit has slightly improved (r^2^ increased from 0.3654 to 0.3988)
* Model is more parsimonious

Model fit does not always improve, sometimes it worsens, which could indicate correlations between variables influencing the model. 


**That's it for today! Any questions feel free to post to Ed.**

## References

* Australian Bureau of Statistics (ABS), 2015, Feature Article: Murray-Darling Basin, retrieved:18/06/21, from https://www.abs.gov.au/AUSSTATS/abs@.nsf/Lookup/1301.0Chapter3042009%E2%80%9310
* Murray-Darling Basin Authority (MDBA), 2020. The Murray-Darling Basin and water management fact sheet. Retrieved:18/06/21 from https://www.mdba.gov.au/sites/default/files/pubs/The-murray-darling-basin-and-water-management-fact-sheet.pdf



