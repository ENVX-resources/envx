---
title: "ENVX1002 Tutorial week 12"
author: 
  - Liana Pozza
  - ----
  - "**ENVX1002 Introduction to Statistical Methods**"
  - School of Life and Environmental Science
  - The University of Sydney
  - ----
output: 
  learnr::tutorial:
    theme: cosmo
    language: 
      en:
        button:
          nexttopic: Next Page
          previoustopic: Previous Page
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(ggplot2)
knitr::opts_chunk$set(
	cache = TRUE,
	output = FALSE
)
```

## What we will cover in this tutorial

In this week's tutorial we will be doing an exploration to determine the most suitable model for our data. In our exploration We will draw upon the non-linear models covered in the week 12 lectures and how to fit them. 

### The problem

I would like to find a suitable model to fit relationship between the number of Anthrax cases in domestic animals in Europe changed over time from 2005-2017.

Anthrax is a disease caused by the bacteria known as *Bacillus anthracis*, which is naturally occurring in soil and can remain there for a substantial amount of time (CDC, 2022). Grazing animals may ingest the spores and become infected, with the disease eventually killing the host (Sweeney et al. 2011). Humans can become infected if they make contact with infected animals or animal products. It is an issue of concern both for animal welfare and human health, so it is worth looking at.

### The data

This week's tutorial data comes from the World Organisation for Animal Health World Animal Health Information System (OIE, 2020). The database is compiled from data contained within official reports submitted by Veterinary services of member and non-member countries around the world.

It is a huge database, so I used the [visualisation tool on the website](https://wahis.oie.int/#/dashboards/qd-dashboard) to select a single disease of interest (Anthrax) and a single location (Europe). I was then able to download the data as an excel file, and then clean the data in R by averaging the number cases across Europe by year with the `aggregate()` function in R.

I also converted the Year variable into a vector of consecutive numbers representing time steps, rather than leaving it as the year. This makes things easier for R and makes the output easier to interpret.

Download the data by clicking the button below:

```{r message=FALSE, echo=FALSE}

downloadthis::download_file(
  path = "ENVX1002_tut12.csv",
  output_name = "ENVX1002_tut12",
  button_label = "Download ENVX1002_tut12.csv",
  button_type = "danger",
  has_icon = TRUE,
  icon = "fa fa-save",
  self_contained = FALSE
)
```

### Data dictionary

This week it is simple, but nice to have clearly outlined. 

* Year = year the total number of anthrax cases were recorded, has been transformed into a vector ranging from 1 (representing 2005) to 13 (representing 2017).

* Cases = Mean number of Anthrax cases for each year calculated across all European countries and species of animals (e.g. goats, cattle).

### Read in data

```{r read}

anthrax = read.csv("ENVX1002_tut12.csv", header=TRUE) 
# header=TRUE tells R to read the first row as the column headings, not data
# Transform into time steps rather than years
anthrax$Year = 1:nrow(anthrax)
```

###
Once we have read the data in, we can look at it as a whole, and look at the structure to ensure the data have been read in correctly. 

```{r first_look}
anthrax # As it is a small dataset, can look at it directly in the console
str(anthrax) 
```

Using the `str()` function tells us the data has been read in correctly - `Year` is an integer and `Cases` is numeric. 

Numeric variables can be read in as factors or characters if there are certain NA strings that R doesn't recognise, e.g. using a '-' or a number with a character in it, e.g. '9E26'. If this did happen, we can tell R how to read these NA strings when we read in the data. 

## Exploratory analysis

### Summary statistics

As usual, we need to have an understanding about the distribution of the data, so using the `summary` function we can look at the central values, as well as the range:

```{r summarystats} 

summary(anthrax)

```

From our summary we can see the number of cases range from 2.565 to 115.875, and there seems to be quite a skew, evident in the mean and medians being dissimilar. 

###
To further demonstrate this we can do a quick boxplot and histogram of the number of cases: 

```{r boxbox} 
# Set visual display
par(mfrow=c(1,2))

boxplot(anthrax$Cases)
hist(anthrax$Cases)

```

In the boxplot we can see a skew as the bar representing the median isn't in the centre of the grey box, and the whiskers are not symmetrical. The histogram is also not symmetrical supporting our idea that the variable is skewed. 

As we can see some skewness happening, we could try to transform depending on the tests we are using/models we are fitting. In the meantime we will leave it untransformed. 

### Any relationship?

If we are unsure what to expect, first thing we can do it plot the two variables:

```{r simple_plot}

par(mfrow=c(1,1))

plot(anthrax$Year, anthrax$Cases)

```

Can we see any sort of trend occurring?

###
If we think it is linear, we can also calculate the correlation coefficient:

```{r cor}

cor(anthrax)

```

The correlation coefficient tells us there is a strong, positive, linear relationship occurring whereas our plot tells us there may be a stronger non-linear relationship occurring. 

## Linear (straight line) models

### Simple linear regression

As we found through or correlation coefficient there was a strong linear relationship occurring, we can first try fitting a simple linear regression. This is quite handy, as it ties in with parsimony - we are trying the simplest model first. 

```{r fitmod}

mod = lm(Cases ~ Year, data=anthrax)

```

###
For our simple linear regression we would be able to do hypothesis testing which assumes a few things. We therefore need to check our assumptions.

###

```{r assumptions, fig.height=7}

# As we are doing hypothesis testing 
par(mfrow=c(2,2))
plot(mod)

```

* Residual vs fitted: NOT MET. Points follow a quadratic trend, line isn't straight. 
* Normal Q-Q: MET. Most points follow the 45 degree line. 
* Scale-Location: NOT MET. Points seem to follow a cyclic trend (W), not evenly scattered. 
* Residuals vs Leverage: NOT MET. Looks strange, one value outside the 0.5 dotted boundary in top right corner, and other points close to the boundary.

We can conclude the assumptions have not been met, so we would need to consider transforming the response variable, or look at using an alternative model. 

###
First we can try transforming the response to try linearising the relationship:

```{r fitlogmod}

mod_log = lm(log(Cases) ~ Year, data=anthrax)

```

Now we can check the assumptions again: 

```{r logmod_assumptions, fig.height=7}

# As we are doing hypothesis testing 
par(mfrow=c(2,2))
plot(mod_log)

```

* Residual vs fitted: NOT MET. Line is straighter, but points still follow a trend rather than an even scatter. 
* Normal Q-Q: MET. Most points follow the 45 degree line. If comparing to the previous QQ plot, looks worse and so could argue it is not met.  
* Scale-Location: NOT MET. Points seem to follow less of a cyclic trend after transformation, but they are still not evenly scattered. 
* Residuals vs Leverage: NOT MET. Looks better, but single value now lies outside the second dotted boundary (cooks distance = 1) in top right corner. 

In this case logging the response hasn't really helped us, but that's okay! we have more in our modelling toolbox to work with. 

### Plot the models

Although our assumptions were not met, let's plot the models we have so far and see how well they fit the points. We can see the model with `log(Cases)` fits the points better than the untransformed linear model, but only slightly.

These plots with `ggplot()` function 1) set up the dataframe and variables of interest, 2) plot points with `geom_point()`, 3) overlay the fitted line from our model by combining `geom_line()` with `predict(mod)`, 4) add titles with `labs()` and 5) use `theme_classic()` which does not have grid lines.

```{r plot_lm}
par(mfrow=c(1,2))

# overlay plot
ggplot(anthrax, aes(x=Year, y=Cases)) +
  geom_point() +
  geom_line(y = predict(mod), color = "red") +
  labs(title = "Linear") +
  theme_classic()

ggplot(anthrax, aes(x=Year, y=log(Cases))) + # transform Cases
  geom_point() +
  geom_line(y = predict(mod_log), color = "blue") + 
  labs(title = "Log transformed linear") +
  theme_classic()

```

###
This slightly better fit is also evident in the model summaries, where there is only a difference of about 0.1 in the multiple R^2^ between the untransformed and logged model. 

```{r summary_lm}

# Model with untransformed Cases 
summary(mod) 

# Cases = -30.63 + 9.96 * Year 

# Model with Cases log transformed  
summary(mod_log) 

# log(Cases) = 0.59 + 0.33 * Year 
```

While we found our assumptions were not met, we are still able to look at the model summary, we just cannot interpret our t-test results with confidence.

**Best model so far: transformed linear model (Multiple R^2^ = 0.899)**

## Quadratic polynomial

###
When looking at the original plot we saw the points start to gradually increase in a curving trend, so we could try a polynomial next.

```{r fit_mod_quad}

# Set up time-squared column
anthrax$Year2 = I(anthrax$Year^2)

mod_quad = lm(Cases ~ Year + Year2, data = anthrax)

```

###
Because we are no longer fitting a linear relationship like MLR or SLR, we don't check the assumptions and we are testing the hypotheses in a slightly different way. 

```{r summary_mod_quad}

summary(mod_quad)

# Cases = 12.52 - 7.31 * Year + 1.23 * Year^2 
```

For polynomials we are only testing the hypothesis of the highest order, i.e. the quadratic term in this case. Is the quadratic term significant?

In this case, it is significant, so it is currently looking better than our original linear models. We can also see the model fits very well, with an adjusted R^2^ of 0.9666. We can say our model accounts for 97% of variation in case numbers. 

**Best model so far: quadratic model (Adjusted R^2^ = 0.967, RSE = 7.77)**

### Plot the model

To get a visual understanding of the model, we can overlay the fitted line onto our plot with `geom_line(y = predict(mod_quad))`.

```{r plot_mod_quad}
par(mfrow=c(1,1)) # reset visual

ggplot(anthrax, aes(x=Year, y=Cases)) +
  geom_point() +
  geom_line(y = predict(mod_quad), color = "green") +
  labs(title = "Quadratic") +
  theme_classic()

```

This is very nice that our model fits, but does it make sense?

The quadratic curve fits quite well to our points, and it is easier to interpret than a true non-linear model. The downside is what the curve is telling us, and how it would go if we wanted to extrapolate further into the future. 

### How about a cubic polynomial?

```{r fit_mod_cub}
# Set up time-cubed column
anthrax$Year3 = I(anthrax$Year^3)

mod_cub = lm(Cases ~ Year + Year2 + Year3, data = anthrax)

summary(mod_cub)

# Cases = 19.78 - 12.58 * Year + 2.14 * Year^2 - 0.04 * Year^3
```

Unlike the quadratic model, the predictors are now all non-significant, and the R^2^ adjusted is slightly lower for the cubic model. When provided with two models with similar outputs, we select the simplest, which is the one with fewer predictors. 

### Plot the model

This time we overlay the cubic model onto the previous quadratic plot but make the line a different colour.

```{r plot_mod_cub}

ggplot(anthrax, aes(x=Year, y=Cases)) +
  geom_point() +
  geom_line(y = predict(mod_quad), color = "green") +
  geom_line(y = predict(mod_cub), color = "orange") +
  labs(title = "Polynomials") +
  theme_classic()

```

It is hard to determine visually, but the principle of parsimony and statistics tell us the quadratic model is the better fit. The cubic model is more complex and does not provide any additional information - the cubic term is also not significant, so there is no benefit in the the extra term.

**Best model so far: quadratic model (R^2^ = 0.967, RSE = RSE = 7.77)**

## Exponential growth model

###
Next we can try fitting our data to a non-linear model to see if it makes more sense for what we are doing. As the number of cases is increasing over time, we could start with an exponential growth curve. 

The general structure for an exponential growth curve is: 

$y=y_0e^{kx}$

where 

- $y$ is the number of cases in the year $x$, 
- $y_0$ is the number of cases at time 0 (2005) and 
- $k$ is the rate constant.

This type of fitting is slightly different to our linear models, as rather than fitting the model to the data, we are now fitting data to a specific model. 

We will use the `nls` function to fit our model. This function requires us to specify a set of starting values, similar to what we have been doing in Excel with Solver. 

###

Our starting values: 

- $y_0$: Looking at the data, we can see the number of cases in 2005 (this is time=0), was ~5
- A bit more effort for this, we can calculate k using the following equation: 

$$
slope = k = \frac{log_e y_{max} - log_e y_{min}}{x_{max} - x_{min}}
$$  

So applied to our data, k would be: 

$$
slope = k = \frac{log_e 115.875 - log_e 2.565217}{2017-2005} = \frac{3.810469}{12}  = 0.3175391
$$  

And we can calculate it in R as follows: 

```{r}

k = (log(max(anthrax$Cases))- log(min(anthrax$Cases)))/(max(anthrax$Year)-min(anthrax$Year))

# could also use: 
# summary(lm(log(anthrax$Cases)~anthrax$Year))
# Coeff for Year = k = 0.33295
```

###
Once we have worked out a decent start value for k, we can fit the model:
```{r}
mod_exp <- nls(Cases ~ y0 * exp(k * Year), data = anthrax, start = list(y0 = 5, k = k), trace=T)

summary(mod_exp)

# Cases = 3.68275 * exp(0.27445 * Year)
```

**Best model so far: quadratic model (R^2^ = 0.967, RSE = RSE = 7.77)**

###

We can then get a visual of the model fit:

```{r plot_mod_exponential}
ggplot(anthrax, aes(x=Year, y=Cases)) +
  geom_point() +
  geom_line(y = predict(mod_quad), color = "green") +
  geom_line(y = predict(mod_exp), color = "red") +
  labs(title = "Exponential") +
  theme_classic()

```

The model fits alright but not as well as the quadratic model. Neither the quadratic model or exponential model would be suitable for extrapolation (anthrax cases would reach infinity). At some point we would expect resources to run out and bacterial growth to slow. This is where a logistic model may be handy for us. 

## Logistic model

###
Logistic models are often used to model disease outbreaks as there is a point where growth should stabilise, rather than continue increasing exponentially as you would see with an exponential model.

###
This point where the curve flattens is known as the 'carrying capacity' and is denoted by `Asym` (asymptote) in the equation below:

$$ y = \frac{Asym}{1+e^{\frac{xmid-x}{scal}}} $$
where

- $Asym$ is the upper limit: the maximum value of $y$.
- $xmid$ is the value of $x$ when $y$ is halfway between the lower and upper limits (inflection point).
- $scal$ is the rate of change: the rate at which $y$ approaches the upper limit.

###

Commonly used to model growth that has a sigmoid shape, i.e. where growth is initially slow, then picks up to a maximum, then slows down again as the system reaches a maximum.

We will use a self-starting function: `SSlogis()`.

```{r}
mod_logis <- nls(Cases ~ SSlogis(Year, Asym, xmid, scal), data = anthrax, trace=T)
summary(mod_logis)

# Cases = 131.11 / (1 + exp((9.85 - Year)/(1.49)))

```

This model as a residual standard error (RSE) of 5.81 - which is lower than the quadratic model.

**Best model so far: logistic model (RSE = 5.81)**

###

And then we can also plot the mode to see how well the model fits visually. 

```{r plot_mod_logistic}

ggplot(anthrax, aes(x=Year, y=Cases)) +
  geom_point() +
  geom_line(y = predict(mod_quad), color = "green") +
  geom_line(y = predict(mod_logis), color = "darkgrey") +
  labs(title = "Logistic") +
  theme_classic()

```

Towards the bottom of the plot, the line does not fit the points as well as the exponential or quadratic, but up the top of the plot, we can see the slope is starting to plateau and reflects what is happening with the points. 

## Final comparisons

###
For any model object, we can extract the residual squared error (RSE) by calling the function and specifying the 'sigma' output, i.e. `summary(mod)$sigma`.

```{r}
# directly put the RSE values into a table
RSE = c(linear = summary(mod)$sigma,
         # log_linear = summary(mod_log)$sigma, # given we have log-transformed the response, we can't compare the RSE directly
         quadratic = summary(mod_quad)$sigma,
         cubic = summary(mod_cub)$sigma,
         exponential = summary(mod_exp)$sigma,
         logistic = summary(mod_logis)$sigma)

# plot table nicely with `kable()` function
knitr::kable(RSE, digits = 2, # 2 decimal places
             col.names = c("Model", "Residual Standard Error"), 
             caption = "Residual standard errors for each model")
```

The model with the lowest residual standard error is the logistic model. Thus we could say that the logistic model is most suitable for the data we have and our aims. 

###
Let's overlay our models onto the plot, with one line per plot. We can backtransform the log model to see how it fits with the other models.

```{r plot_mod_all}
#| code-fold: TRUE

ggplot(anthrax, aes(x=Year, y=Cases)) +
  geom_line(y = predict(mod_logis), color = "darkgrey", size = 2) +
  geom_line(y = predict(mod), color = "red") +
  geom_line(y = exp(predict(mod_log)), color = "blue") + # back-transform
  geom_line(y = predict(mod_quad), color = "green") +
  geom_line(y = predict(mod_cub), color = "orange") +
  geom_line(y = predict(mod_exp), color = "purple") +
  geom_point(size = 3) +
  labs(title = "All models") +
  theme_classic()

```

## Summary

We found, based on RSE, that the logistic model was best suitable to our Anthrax data. The downside about the logistic model is that unlike a simple linear model, it is harder to interpret the fit, i.e. we can't really calculate an R^2^ and we can't easily do hypothesis testing. 

Logistic models are often used to model disease outbreak because of the built-in asymptote, or carrying capacity.Understanding when this carrying capacity may be met is helpful for disease management and health system planning. 

Recall COVID-19; this would let us know the maximum number of people sick at one time and when this peak would occur. This helps to know how much and when we need resources --  and inform lockdowns!

###

That's it for today, this is your initial glimpse at fitting non-linear models, and you will have a chance to build upon your knowledge in the lab classes. Any questions feel free to post to Ed. 

## References

* World Organisation for Animal Health (OIE), 2020, OIE World Animal Health Information System, https://wahis.oie.int/#/dashboards/qd-dashboard, date Accessed: 12/05/22
* Centers for Disease Control and Prevention (CDC), 2022, What Is Anthrax?, Accessed: 14/5/2022, from https://www.cdc.gov/anthrax/basics/index.html
* Sweeney, D.A., Hicks, C.W., Cui, X., Li, Y. and Eichacker, P.Q., 2011. Anthrax infection. American journal of respiratory and critical care medicine, 184(12), pp.1333-1341.


